{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85065d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time, random\n",
    "import os, json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "# from functools import partial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddec33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"http://lorax-serving-service:3000/v1/generate\"\n",
    "url2 = \"http://lorax-serving-service:80/v1/generate\"\n",
    "# url = \"https://refract.fosfor.com/vllm/magicoder/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "# request_payload_file = '/data/Promptshett_codegen_50.txt'\n",
    "# report_path = '/data/vLLM_Base_1gpu.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4aa3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter1 = 'NLG'\n",
    "adapter2 = 'MQL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2c937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payload = {\n",
    "  \"prompt\": \"What is the meaning of life?\",\n",
    "  \"llm_config\": {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 0.75,\n",
    "    \"top_k\": 15,\n",
    "    \"top_p\": 1\n",
    "  },\n",
    "  \"adapter_name\": adapter2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\"prompt\": \"Problem: Create an animated dropdown menu in CSS that appears when a button is clicked.Input: Button element selector, dropdown menu element selector.Output: None (animate the dropdown menu).\", \n",
    "#            \"max_tokens\": 200,\n",
    "#            \"temperature\": 0,\n",
    "#            \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a0dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def calculate_execution_time(*args, **kwargs):\n",
    "        global df\n",
    "        start_time = time.time()\n",
    "        result, a,b= func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        data = {'Prompt_No':b,'Prompt':a,'Response':result.text, 'Response_status':result.status_code, 'Time (seconds)':f'{execution_time:.6f}'}\n",
    "        df = df._append(data, ignore_index=True)\n",
    "        print(f\"Execution time: {execution_time:.6f} seconds \\n\\n\")\n",
    "        return result,a,b\n",
    "    return calculate_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f946126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(file_path, df):\n",
    "#     print(\"Saving report\\n\", df)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed2a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_decorator\n",
    "def inference(prompt_index, payload_data=None):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json', 'accept': 'application/json' #'AUTHORIZATION': f'Bearer {lltoken}'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url2, headers=headers, json=payload_data)\n",
    "#     print(f\"Prompt {prompt_index}==> {payload_data['prompt']} \\n {response.text}\")\n",
    "    print(f\"Prompt {prompt_index}==> Response \\n {response.text}\")\n",
    "    return response, payload_data['prompt'], prompt_index\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ea6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1==> Response \n",
      " \"An error has occurred in BentoML user code when handling this request, find the error details in server logs\"\n",
      "Execution time: 0.058247 seconds \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result = inference(1, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78831f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Model Inference(Request) Same Payload\n",
    "# if __name__ == \"__main__\":\n",
    "#     for i in range(5):\n",
    "#         print(f\"loop {i}+++++++++++++++++++++++++++++\")\n",
    "#         with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "#             futures = [executor.submit(inference, srno, payload) for srno in range(1)]\n",
    "#             concurrent.futures.wait(futures)\n",
    "# #     save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
