{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85065d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os, json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "# from functools import partial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddec33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"http://vllm-serving-service:8888/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "report_path = '/data/vLLM_Base_1gpu.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "998fb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
    "follow instruction and response accuratly. finally only generate respose without instruction. \n",
    "\n",
    "@@Instruction\n",
    "this is the sample dbt model\n",
    "with customer_revenue as (\n",
    "select\n",
    "customer_id,\n",
    "sum(amount) as total_revenue\n",
    "from\n",
    "{ ref('orders') }\n",
    "group by 1\n",
    ")\n",
    "select\n",
    "c.customer_id,\n",
    "c.first_name,\n",
    "c.last_name,\n",
    "cr.total_revenue\n",
    "from\n",
    "{ source('master_data','customers') } c\n",
    "left join customer_revenue cr on c.customer_id = cr.customer_id\n",
    "\n",
    "@@response\n",
    "Below is the sample dbt model documentation generated for above instruction dbt model:\n",
    "\n",
    "* Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
    "* Dependencies:\n",
    "* orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
    "* customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
    "* Transformation:\n",
    "* The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
    "* The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
    "* Example Usage:  The resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
    "\n",
    "@@ Instruction\n",
    "create similar dbt model documentation for following dbt model code\n",
    " {% snapshot users_snapshot %}  \n",
    "{{\n",
    "  config(      \n",
    "    target_schema='snapshots',      \n",
    "    strategy='timestamp',      \n",
    "    unique_key='id',      \n",
    "    updated_at='updated_at'    \n",
    "  )  \n",
    "}}  \n",
    "  select * \n",
    "  from {{ source('raw','users') }}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\"prompt\": \"Problem: Create an animated dropdown menu in CSS that appears when a button is clicked.Input: Button element selector, dropdown menu element selector.Output: None (animate the dropdown menu).\", \n",
    "#            \"max_tokens\": 200,\n",
    "#            \"temperature\": 0,\n",
    "#            \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd035b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\": prompt, \n",
    "           \"max_tokens\": 500,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c55110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_payloads(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            prompt = json.loads(line.strip())\n",
    "            yield prompt['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a0dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def calculate_execution_time(*args, **kwargs):\n",
    "        global df\n",
    "        start_time = time.time()\n",
    "        result, a,b= func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        data = {'Prompt_No':b,'Prompt':a,'Response':result.text, 'Response_status':result.status_code, 'Time (seconds)':f'{execution_time:.6f}'}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        print(f\"Execution time: {execution_time:.6f} seconds \\n\\n\")\n",
    "        return result,a,b\n",
    "    return calculate_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f946126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(file_path, df):\n",
    "    print(\"Saving report\\n\", df)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed2a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_decorator\n",
    "def inference(prompt_index, payload_data=None):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, json=payload_data)\n",
    "    print(f\"Prompt {prompt_index}==> {payload_data['prompt']} \\n {response.text}\")\n",
    "    return response, payload_data['prompt'], prompt_index\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b1003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_worker(thread, payload):\n",
    "    prompts = read_payloads(request_payload_file)\n",
    "    try:\n",
    "        for line, prompt in enumerate(prompts,start=0):\n",
    "            payload = {**payload, 'prompt': prompt}\n",
    "            print(f\"Prompting prompt {line+1}\")\n",
    "            a,b,c,_ = inference(line, payload)\n",
    "            print(f\"Finished Prompting prompt {line+1}\")\n",
    "    except Exception as e:\n",
    "        print(a,b,c)\n",
    "        print(f\"Error in thread {thread} - prompt {line}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c706b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Inference(Request)\n",
    "# if __name__ == \"__main__\":\n",
    "#     global df\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "#         futures = [executor.submit(my_worker, _, payload) for _ in range(30)]\n",
    "#         concurrent.futures.wait(futures)\n",
    "#     save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78831f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0+++++++++++++++++++++++++++++\n",
      "Prompt 0==> You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
      "follow instruction and response accuratly. finally only generate respose without instruction. \n",
      "@@Instruction\n",
      "this is the sample dbt model\n",
      "with customer_revenue as (\n",
      "select\n",
      "customer_id,\n",
      "sum(amount) as total_revenue\n",
      "from\n",
      "{ ref('orders') }\n",
      "group by 1\n",
      ")\n",
      "select\n",
      "c.customer_id,\n",
      "c.first_name,\n",
      "c.last_name,\n",
      "cr.total_revenue\n",
      "from\n",
      "{ source('master_data','customers') } c\n",
      "left join customer_revenue cr on c.customer_id = cr.customer_id\n",
      "@@response\n",
      "Below is the sample dbt model documentation generated for above instruction dbt model:\n",
      "* Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
      "* Dependencies:\n",
      "* orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
      "* customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
      "* Transformation:\n",
      "* The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
      "* The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
      "* Example Usage:  The resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
      "@@ Instruction\n",
      "create similar dbt model documentation for following dbt model code\n",
      " {% snapshot users_snapshot %}  \n",
      "{{\n",
      "  config(      \n",
      "    target_schema='snapshots',      \n",
      "    strategy='timestamp',      \n",
      "    unique_key='id',      \n",
      "    updated_at='updated_at'    \n",
      "  )  \n",
      "}}  \n",
      "  select * \n",
      "  from {{ source('raw','users') }} \n",
      " {\"id\":\"cmpl-c52ac07c5d5440b586ccd3c9146b80df\",\"object\":\"text_completion\",\"created\":2656,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"  \\n{% endsnapshot %}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":493,\"total_tokens\":993,\"completion_tokens\":500}}\n",
      "Execution time: 24.205327 seconds \n",
      "\n",
      "\n",
      "Saving report\n",
      "   Prompt_No                                             Prompt  \\\n",
      "0         0  You are an exceptional dbt analytics engineer ...   \n",
      "1         0  You are an exceptional dbt analytics engineer ...   \n",
      "2         0  You are an exceptional dbt analytics engineer ...   \n",
      "\n",
      "                                            Response Response_status  \\\n",
      "0  {\"object\":\"error\",\"message\":\"This model's maxi...             400   \n",
      "1  {\"object\":\"error\",\"message\":\"This model's maxi...             400   \n",
      "2  {\"id\":\"cmpl-c52ac07c5d5440b586ccd3c9146b80df\",...             200   \n",
      "\n",
      "  Time (seconds)  \n",
      "0       0.050200  \n",
      "1       0.043989  \n",
      "2      24.205327  \n"
     ]
    }
   ],
   "source": [
    "# #Model Inference(Request) Same Payload\n",
    "if __name__ == \"__main__\":\n",
    "    # Using the generator function to read lines \n",
    "    prompts = list(read_payloads(request_payload_file))\n",
    "    index=0\n",
    "    global df\n",
    "    for i in range(1):\n",
    "        print(f\"loop {i}+++++++++++++++++++++++++++++\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            futures = [executor.submit(inference, srno, payload) for srno in range(1)]\n",
    "            concurrent.futures.wait(futures)\n",
    "    save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    print(f\"Processing data: {data}\")\n",
    "\n",
    "def worker():\n",
    "    # Create a new generator instance for each thread\n",
    "    gen = my_generator()\n",
    "    \n",
    "    try:\n",
    "        for value in gen:\n",
    "            process_data(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in thread: {e}\")\n",
    "    finally:\n",
    "        # Ensure proper cleanup (optional)\n",
    "        print(\"Thread cleanup\")\n",
    "\n",
    "# Set the number of threads\n",
    "num_threads = 3\n",
    "\n",
    "# Outer loop for reiterating\n",
    "for _ in range(2):  # Adjust the number of iterations as needed\n",
    "    # Create a ThreadPoolExecutor with the specified number of threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        # Submit tasks to the ThreadPoolExecutor\n",
    "        futures = [executor.submit(worker) for _ in range(num_threads)]\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        concurrent.futures.wait(futures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
