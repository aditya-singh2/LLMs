{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85065d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time, random\n",
    "import os, json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "# from functools import partial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddec33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"http://vllm-serving-service:8888/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "# request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "request_payload_file = '/data/Promptshett_codegen_50.txt'\n",
    "report_path = '/data/vLLM_50prompts.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55105034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Prompt_No, Prompt, Response, Response_status, Time (seconds)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"https://refract.fosfor.com/v1/completions\"\n",
    "lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "# request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "request_payload_file = '/data/Promptshett_codegen_50.txt'\n",
    "report_path = '/data/vLLM_50prompts.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "998fb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=[\"\"\"You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
    "follow instruction and response accuratly. finally only generate respose without instruction. \n",
    " \n",
    "@@Instruction\n",
    "this is the sample dbt model\n",
    "with customer_revenue as (\n",
    "select\n",
    "customer_id,\n",
    "sum(amount) as total_revenue\n",
    "from\n",
    "{ ref('orders') }\n",
    "group by 1\n",
    ")\n",
    " \n",
    "select\n",
    "c.customer_id,\n",
    "c.first_name,\n",
    "c.last_name,\n",
    "cr.total_revenue\n",
    "from\n",
    "{ source('master_data','customers') } c\n",
    "left join customer_revenue cr on c.customer_id = cr.customer_id\n",
    "\n",
    "@@response\n",
    "Below is the sample dbt model documentation generated for above instruction dbt model:\n",
    " \n",
    "* Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
    "* Dependencies:\n",
    "* orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
    "* customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
    "* Transformation:\n",
    "* The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
    "* The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
    "* Example Usage:  The resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
    "\n",
    "@@ Instruction\n",
    "create similar dbt model documentation for following dbt model code\n",
    " {% snapshot users_snapshot %}  \n",
    " \n",
    "{{\n",
    "  config(      \n",
    "    target_schema='snapshots',      \n",
    "    strategy='timestamp',      \n",
    "    unique_key='id',      \n",
    "    updated_at='updated_at'    \n",
    "  )  \n",
    "}}  \n",
    " \n",
    "  select * \n",
    "  from {{ source('raw','users') }}\n",
    " \n",
    "{% endsnapshot %}\n",
    "\n",
    "@@ response\"\"\",\n",
    "       \"Generate a DBT model which gives me variants of the products which has highest sales\",\n",
    "       \"Construct a DBT view model in the 'staging' schema, linking 'jaffle_shop' orders with payment information from 'stg_payments', summarizing successful payments per order, and merging with order details to handle potential missing payment scenarios.\",\n",
    "       \"Define an incremental dbt model named user_activity_daily with a unique key on date_day for daily active users. Implement the 'delete+insert' strategy for incremental updates.\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "201050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " payload = {\"prompt\": \"Problem: Create an animated dropdown menu in CSS that appears when a button is clicked.Input: Button element selector, dropdown menu element selector.Output: None (animate the dropdown menu).\", \n",
    "           \"max_tokens\": 200,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd035b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\": prompt, \n",
    "           \"max_tokens\": 2400,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30c55110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_payloads(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            prompt = line.strip()\n",
    "#             prompt = json.loads(line.strip())\n",
    "            yield prompt\n",
    "#             yield prompt['payload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a0dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def calculate_execution_time(*args, **kwargs):\n",
    "        global df\n",
    "        start_time = time.time()\n",
    "        result, a,b= func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        data = {'Prompt_No':b,'Prompt':a,'Response':result.text, 'Response_status':result.status_code, 'Time (seconds)':f'{execution_time:.6f}'}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        print(f\"Execution time: {execution_time:.6f} seconds \\n\\n\")\n",
    "        return result,a,b\n",
    "    return calculate_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f946126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(file_path, df):\n",
    "    print(\"Saving report\\n\", df)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed2a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_decorator\n",
    "def inference(prompt_index, payload_data=None):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\"AUTHORIZATION\": f\"Bearer {lltoken}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, json=payload_data)\n",
    "#     print(f\"Prompt {prompt_index}==> {payload_data['prompt']} \\n {response.text}\")\n",
    "    print(f\"Prompt {prompt_index}==> Response \\n {response.text}\")\n",
    "    return response, payload_data['prompt'], prompt_index\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b1003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_worker(thread, payload):\n",
    "    prompts = read_payloads(request_payload_file)\n",
    "    try:\n",
    "        for line, prompt in enumerate(prompts,start=0):\n",
    "            payload = {**payload, 'prompt': prompt}\n",
    "            print(f\"Prompting prompt {line+1}\")\n",
    "            a,b,c,_ = inference(line, payload)\n",
    "            print(f\"Finished Prompting prompt {line+1}\")\n",
    "    except Exception as e:\n",
    "        print(a,b,c)\n",
    "        print(f\"Error in thread {thread} - prompt {line}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c706b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Inference(Request)\n",
    "# if __name__ == \"__main__\":\n",
    "#     global df\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "#         futures = [executor.submit(my_worker, _, payload) for _ in range(30)]\n",
    "#         concurrent.futures.wait(futures)\n",
    "#     save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78831f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "loop 0+++++++++++++++++++++++++++++\n",
      "loop 1+++++++++++++++++++++++++++++\n",
      "Prompt 3==> Response \n",
      " {\"id\":\"cmpl-e86ef2c5c5664b1a819dfbe38439b6a1\",\"object\":\"text_completion\",\"created\":10371,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\nAssuming you have two tables:\\n\\n1. Employees:\\n\\n| id | name | manager_id |\\n|----|------|------------|\\n| 1  | John | 2          |\\n| 2  | Jane | 3          |\\n| 3  | Bob  | 4          |\\n| 4  | Alice| 5          |\\n\\n2. Tickets:\\n\\n| id | employee_id | priority |\\n|----|-------------|----------|\\n| 1  | 1           | high     |\\n| 2  | 2           | medium   |\\n| 3  | 3           | high     |\\n| 4  | 4           | low      |\\n| 5  | 5           | high     |\\n\\nThe SQL query should return the details of the manager whose employee has been assigned high priority tickets.\\n\\nHere is the SQL query:\\n\\n```sql\\nSELECT e.name AS Manager_Name, e.id AS Manager_ID\\nFROM Employees e\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":24,\"total_tokens\":224,\"completion_tokens\":200}}\n",
      "Prompt 0==> Response \n",
      " {\"id\":\"cmpl-b83bb7864b9249be9c566629d8c49892\",\"object\":\"text_completion\",\"created\":10371,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\nAssuming you have two tables:\\n\\n1. `employees` table with columns: `employee_id`, `name`, `country`, `client_id`\\n2. `clients` table with columns: `client_id`, `client_name`, `country`\\n\\nThe SQL query would look something like this:\\n\\n```sql\\nSELECT e.employee_id, e.name, e.country, c.client_name, c.country\\nFROM employees e\\nJOIN clients c ON e.client_id = c.client_id\\nWHERE c.country = 'US'\\n```\\n\\nThis SQL statement will join the `employees` and `clients` tables on the `client_id` column, and then filter the results to only include rows where the `country` of the `clients` table is 'US'. The resulting table will contain the `\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":26,\"total_tokens\":226,\"completion_tokens\":200}}\n",
      "Prompt 8==> Response \n",
      " {\"id\":\"cmpl-b4645a4cefd245d5b683b9b548869dfd\",\"object\":\"text_completion\",\"created\":10371,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\nI have a table named \\\"orders\\\" which has columns like order_id, customer_id, payment_method, order_date, etc.\\n\\nI want to generate a dbt model which gives me customer details who has used credit card for payment in last month.\\n\\nHere is my current dbt model:\\n\\n```sql\\n{{ config(materialized='table') }}\\n\\nwith orders as (\\n    select * from {{ ref('stg_orders') }}\\n),\\n\\ncredit_card_payments as (\\n    select \\n        customer_id,\\n        order_date\\n    from orders\\n    where payment_method = 'credit_card'\\n)\\n\\nselect * from credit_card_payments\\n```\\n\\nThis model is not filtering out customers who used credit card for payment in last month. How can I modify this model to achieve that?\\n\\nI tried to add a\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":23,\"total_tokens\":223,\"completion_tokens\":200}}\n",
      "loop 2+++++++++++++++++++++++++++++\n",
      "Prompt 0==> Response \n",
      " {\"id\":\"cmpl-43cc48acf38249fe8aecae0e727b7bef\",\"object\":\"text_completion\",\"created\":10502,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have two tables:\\n1. customers:\\n\\n| customer_id | name |\\n|-------------|------|\\n| 1           | John |\\n| 2           | Jane |\\n\\n2. products:\\n\\n| product_id | product_name | recommendation_score | customer_id |\\n|------------|--------------|-----------------------|-------------|\\n| 1          | Product1     | 5                     | 1           |\\n| 2          | Product2     | 3                     | 1           |\\n| 3          | Product3     | 4                     | 2           |\\n| 4          | Product4     | 2                     | 2           |\\n\\nI want to generate a dbt model that gives me the product information of the maximum recommendation_score for each customer.\\n\\nHere is the SQL query that I want to convert to dbt:\\n\\n```sql\\nSELECT c.customer_id, c.name, p.product_name, p.re\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":21,\"total_tokens\":221,\"completion_tokens\":200}}\n",
      "Prompt 9==> Response \n",
      " {\"id\":\"cmpl-779e1615d54c4c6a83fec7a0350c5e7b\",\"object\":\"text_completion\",\"created\":10502,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have a table named \\\"projects\\\" with columns \\\"project_name\\\" and \\\"purchase_date\\\".\\n\\nI want to generate a sql query for dbt model which gives me the names of the projects whose assets were purchased before the year 2020.\\n\\nHere is the SQL query I'm trying to generate:\\n\\n```sql\\nSELECT project_name\\nFROM projects\\nWHERE purchase_date < '2020-01-01'\\n```\\n\\nHow can I generate this SQL query in dbt?\\n\\nI'm new to dbt and SQL. I'm trying to create a dbt model for this SQL query.\\n\\nI tried creating a dbt model like this:\\n\\n```yaml\\nversion: 2\\n\\nmodels:\\n  - name: project_assets_purchased_before_2020\\n    description: \\\"Names of projects whose assets\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":28,\"total_tokens\":228,\"completion_tokens\":200}}\n",
      "Prompt 3==> Response \n",
      " {\"id\":\"cmpl-7875faaf6a9f40d18ae4f1b64ba1ce03\",\"object\":\"text_completion\",\"created\":10508,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have a table named \\\"projects\\\" with columns \\\"project_name\\\" and \\\"purchase_date\\\".\\n\\nI want to generate a sql query for dbt model which gives me the names of the projects whose assets were purchased before the year 2020.\\n\\nHere is the SQL query I'm trying to generate:\\n\\n```sql\\nSELECT project_name\\nFROM projects\\nWHERE purchase_date < '2020-01-01'\\n```\\n\\nHow can I generate this SQL query in dbt?\\n\\nI'm new to dbt and SQL. I'm trying to create a dbt model for this SQL query.\\n\\nI tried creating a dbt model like this:\\n\\n```yaml\\nversion: 2\\n\\nmodels:\\n  - name: project_assets_purchased_before_2020\\n    description: \\\"Names of projects whose assets\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":28,\"total_tokens\":228,\"completion_tokens\":200}}\n",
      "Prompt 4==> Response \n",
      " {\"id\":\"cmpl-aba07aae0109413aac7ab7d40961ed17\",\"object\":\"text_completion\",\"created\":10508,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have two tables:\\n1. Assets:\\n\\n| asset_id | asset_name |\\n|----------|------------|\\n| 1        | Asset1     |\\n| 2        | Asset2     |\\n| 3        | Asset3     |\\n\\n2. Departments:\\n\\n| department_id | department_name |\\n|----------------|-----------------|\\n| 1              | Dept1           |\\n| 2              | Dept2           |\\n| 3              | Dept3           |\\n\\nAnd a third table:\\n\\n3. Department_Assets:\\n\\n| department_id | asset_id |\\n|----------------|----------|\\n| 1              | 1        |\\n| 1              | 2        |\\n| 2              | 3        |\\n| 3              | 1        |\\n| 3              | 2        |\\n| 3              | 3        |\\n\\nI want to generate a SQL query that will give me a result like\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":19,\"total_tokens\":219,\"completion_tokens\":200}}\n",
      "Prompt 1==> Response \n",
      " {\"id\":\"cmpl-1994fcaf48174d83a1831121ef27e64a\",\"object\":\"text_completion\",\"created\":10508,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have a table named \\\"projects\\\" with columns \\\"project_name\\\" and \\\"purchase_date\\\".\\n\\nI want to generate a sql query for dbt model which gives me the names of the projects whose assets were purchased before the year 2020.\\n\\nHere is the SQL query I'm trying to generate:\\n\\n```sql\\nSELECT project_name\\nFROM projects\\nWHERE purchase_date < '2020-01-01'\\n```\\n\\nHow can I generate this SQL query in dbt?\\n\\nI'm new to dbt and SQL. I'm trying to create a dbt model for this SQL query.\\n\\nI tried creating a dbt model like this:\\n\\n```yaml\\nversion: 2\\n\\nmodels:\\n  - name: project_assets_purchased_before_2020\\n    description: \\\"Names of projects whose assets\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":28,\"total_tokens\":228,\"completion_tokens\":200}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 3+++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# #Model Inference(Request) Same Payload\n",
    "if __name__ == \"__main__\":\n",
    "    # Using the generator function to read lines \n",
    "    prompts = list(read_payloads(request_payload_file))\n",
    "    print(len(prompts))\n",
    "    index=0\n",
    "    global df\n",
    "    for i in range(1000):\n",
    "        print(f\"loop {i}+++++++++++++++++++++++++++++\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = [executor.submit(inference, srno, {**payload, 'prompt': prompts[random.randint(0,49)]}) for srno in range(10)]\n",
    "            concurrent.futures.wait(futures)\n",
    "    save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
