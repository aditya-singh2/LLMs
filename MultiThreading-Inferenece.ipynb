{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85065d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os, json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "# from functools import partial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddec33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"http://vllm-serving-service:8888/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "report_path = '/data/vLLM_Base_1gpu.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998fb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
    "follow instruction and response accuratly. finally only generate respose without instruction. \n",
    " \n",
    "@@Instruction\n",
    "this is the sample dbt model\n",
    "with customer_revenue as (\n",
    "select\n",
    "customer_id,\n",
    "sum(amount) as total_revenue\n",
    "from\n",
    "{ ref('orders') }\n",
    "group by 1\n",
    ")\n",
    " \n",
    "select\n",
    "c.customer_id,\n",
    "c.first_name,\n",
    "c.last_name,\n",
    "cr.total_revenue\n",
    "from\n",
    "{ source('master_data','customers') } c\n",
    "left join customer_revenue cr on c.customer_id = cr.customer_id\n",
    "\n",
    "@@response\n",
    "Below is the sample dbt model documentation generated for above instruction dbt model:\n",
    " \n",
    "* Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
    "* Dependencies:\n",
    "* orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
    "* customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
    "* Transformation:\n",
    "* The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
    "* The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
    "* Example Usage:  The resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
    "\n",
    "@@ Instruction\n",
    "create similar dbt model documentation for following dbt model code\n",
    " {% snapshot users_snapshot %}  \n",
    " \n",
    "{{\n",
    "  config(      \n",
    "    target_schema='snapshots',      \n",
    "    strategy='timestamp',      \n",
    "    unique_key='id',      \n",
    "    updated_at='updated_at'    \n",
    "  )  \n",
    "}}  \n",
    " \n",
    "  select * \n",
    "  from {{ source('raw','users') }}\n",
    " \n",
    "{% endsnapshot %}\n",
    "\n",
    "@@ response\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\"prompt\": \"Problem: Create an animated dropdown menu in CSS that appears when a button is clicked.Input: Button element selector, dropdown menu element selector.Output: None (animate the dropdown menu).\", \n",
    "#            \"max_tokens\": 200,\n",
    "#            \"temperature\": 0,\n",
    "#            \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd035b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\": prompt, \n",
    "           \"max_tokens\": 2400,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c55110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_payloads(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            prompt = json.loads(line.strip())\n",
    "            yield prompt['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a0dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def calculate_execution_time(*args, **kwargs):\n",
    "        global df\n",
    "        start_time = time.time()\n",
    "        result, a,b= func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        data = {'Prompt_No':b,'Prompt':a,'Response':result.text, 'Response_status':result.status_code, 'Time (seconds)':f'{execution_time:.6f}'}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        print(f\"Execution time: {execution_time:.6f} seconds \\n\\n\")\n",
    "        return result,a,b\n",
    "    return calculate_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f946126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(file_path, df):\n",
    "    print(\"Saving report\\n\", df)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed2a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_decorator\n",
    "def inference(prompt_index, payload_data=None):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, json=payload_data)\n",
    "    print(f\"Prompt {prompt_index}==> {payload_data['prompt']} \\n {response.text}\")\n",
    "    return response, payload_data['prompt'], prompt_index\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b1003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_worker(thread, payload):\n",
    "    prompts = read_payloads(request_payload_file)\n",
    "    try:\n",
    "        for line, prompt in enumerate(prompts,start=0):\n",
    "            payload = {**payload, 'prompt': prompt}\n",
    "            print(f\"Prompting prompt {line+1}\")\n",
    "            a,b,c,_ = inference(line, payload)\n",
    "            print(f\"Finished Prompting prompt {line+1}\")\n",
    "    except Exception as e:\n",
    "        print(a,b,c)\n",
    "        print(f\"Error in thread {thread} - prompt {line}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c706b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Inference(Request)\n",
    "# if __name__ == \"__main__\":\n",
    "#     global df\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "#         futures = [executor.submit(my_worker, _, payload) for _ in range(30)]\n",
    "#         concurrent.futures.wait(futures)\n",
    "#     save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "78831f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0+++++++++++++++++++++++++++++\n",
      "Saving report\n",
      "    Prompt_No                                             Prompt  \\\n",
      "0          4  You are an exceptional dbt analytics engineer ...   \n",
      "1          5  You are an exceptional dbt analytics engineer ...   \n",
      "2          1  You are an exceptional dbt analytics engineer ...   \n",
      "3          0  You are an exceptional dbt analytics engineer ...   \n",
      "4          7  You are an exceptional dbt analytics engineer ...   \n",
      "5          1  You are an exceptional dbt analytics engineer ...   \n",
      "6          3  You are an exceptional dbt analytics engineer ...   \n",
      "7          9  You are an exceptional dbt analytics engineer ...   \n",
      "8          4  You are an exceptional dbt analytics engineer ...   \n",
      "9          8  You are an exceptional dbt analytics engineer ...   \n",
      "10        13  You are an exceptional dbt analytics engineer ...   \n",
      "11        15  You are an exceptional dbt analytics engineer ...   \n",
      "12        14  You are an exceptional dbt analytics engineer ...   \n",
      "13        12  You are an exceptional dbt analytics engineer ...   \n",
      "14        11  You are an exceptional dbt analytics engineer ...   \n",
      "15        19  You are an exceptional dbt analytics engineer ...   \n",
      "16        18  You are an exceptional dbt analytics engineer ...   \n",
      "17        20  You are an exceptional dbt analytics engineer ...   \n",
      "18        29  You are an exceptional dbt analytics engineer ...   \n",
      "19        23  You are an exceptional dbt analytics engineer ...   \n",
      "20        24  You are an exceptional dbt analytics engineer ...   \n",
      "21        27  You are an exceptional dbt analytics engineer ...   \n",
      "22        28  You are an exceptional dbt analytics engineer ...   \n",
      "23         7  You are an exceptional dbt analytics engineer ...   \n",
      "24        11  You are an exceptional dbt analytics engineer ...   \n",
      "25         1  You are an exceptional dbt analytics engineer ...   \n",
      "26        15  You are an exceptional dbt analytics engineer ...   \n",
      "27         2  You are an exceptional dbt analytics engineer ...   \n",
      "28        21  You are an exceptional dbt analytics engineer ...   \n",
      "29         6  You are an exceptional dbt analytics engineer ...   \n",
      "30         3  You are an exceptional dbt analytics engineer ...   \n",
      "31        20  You are an exceptional dbt analytics engineer ...   \n",
      "32        28  You are an exceptional dbt analytics engineer ...   \n",
      "33        12  You are an exceptional dbt analytics engineer ...   \n",
      "34        18  You are an exceptional dbt analytics engineer ...   \n",
      "35        19  You are an exceptional dbt analytics engineer ...   \n",
      "36        25  You are an exceptional dbt analytics engineer ...   \n",
      "37         9  You are an exceptional dbt analytics engineer ...   \n",
      "38        27  You are an exceptional dbt analytics engineer ...   \n",
      "39        26  You are an exceptional dbt analytics engineer ...   \n",
      "40        29  You are an exceptional dbt analytics engineer ...   \n",
      "\n",
      "                                             Response Response_status  \\\n",
      "0   {\"id\":\"cmpl-55db482d831642f79419624f1f42da72\",...             200   \n",
      "1   {\"id\":\"cmpl-c077978a5c8f43218ab8252a26184876\",...             200   \n",
      "2   {\"id\":\"cmpl-cedc0951784b41f3b4358f708b9bf33a\",...             200   \n",
      "3   {\"id\":\"cmpl-c7b6cdd133ba4947af66580932993412\",...             200   \n",
      "4   {\"id\":\"cmpl-9e87296bcf4045f2b153a2097d8eafd6\",...             200   \n",
      "5   {\"id\":\"cmpl-4f316cfefd7f40898d2045c28f74aa70\",...             200   \n",
      "6   {\"id\":\"cmpl-93b29df7adb242e9bb1bf28ca38c0852\",...             200   \n",
      "7   {\"id\":\"cmpl-fab3cd8d82c940f8b95e115cb54a848b\",...             200   \n",
      "8   {\"id\":\"cmpl-8135aa9b67d8452f9f7b96c4e08a1e92\",...             200   \n",
      "9   {\"id\":\"cmpl-b2b11c41c6eb488c999e0b5a72053076\",...             200   \n",
      "10  {\"id\":\"cmpl-19b9b8b6724543a294b1dff4fb2c7151\",...             200   \n",
      "11  {\"id\":\"cmpl-e52f6fa6fe57409e8ce652be1dc7c372\",...             200   \n",
      "12  {\"id\":\"cmpl-510e59aa87974ddf8f030f0a79db3875\",...             200   \n",
      "13  {\"id\":\"cmpl-8e07ce8ec5144388947e73a7f0ad21ab\",...             200   \n",
      "14  {\"id\":\"cmpl-3bb84339c85842de9871755819cf17f0\",...             200   \n",
      "15  {\"id\":\"cmpl-c905286c5acb497b996954ba0c9f47ba\",...             200   \n",
      "16  {\"id\":\"cmpl-ba7aa6cf118946cf8b6b77007766293f\",...             200   \n",
      "17  {\"id\":\"cmpl-a9b002751f4e4e3b80da1594ee2614bd\",...             200   \n",
      "18  {\"id\":\"cmpl-a0fc506732eb49189fe8cae7f257f6fb\",...             200   \n",
      "19  {\"id\":\"cmpl-1f88b1f52dae42e5924c792eeaf36d31\",...             200   \n",
      "20  {\"id\":\"cmpl-06482750fa374857b57dac3a719c28a7\",...             200   \n",
      "21  {\"id\":\"cmpl-68d9b147c52b452f911ec82776107993\",...             200   \n",
      "22  {\"id\":\"cmpl-17121db5f6a14a31a92812db696b39ca\",...             200   \n",
      "23  {\"id\":\"cmpl-2dd36346b44c467fa7dcf576aa63560e\",...             200   \n",
      "24  {\"id\":\"cmpl-de7d524f79214edbb7c2c7e00eb23271\",...             200   \n",
      "25  {\"id\":\"cmpl-b4210136178643ab89c90be333d475f4\",...             200   \n",
      "26  {\"id\":\"cmpl-49ffcdbb55dd427494f12144b0670b3c\",...             200   \n",
      "27  {\"id\":\"cmpl-cf0868c2d60449d5b0b20c73193aacbf\",...             200   \n",
      "28  {\"id\":\"cmpl-79270961617a4b5b8a653b815f6430e1\",...             200   \n",
      "29  {\"id\":\"cmpl-2809199cf7f44cce8520f5cd240fcee3\",...             200   \n",
      "30  {\"id\":\"cmpl-036eeaca05234b21afeac09b25211687\",...             200   \n",
      "31  {\"id\":\"cmpl-2af80c8b418f41a4b5cdbf32fc981ee7\",...             200   \n",
      "32  {\"id\":\"cmpl-03df20d4a4524c82b4104b4c4c17866b\",...             200   \n",
      "33  {\"id\":\"cmpl-5d42755787814347b26d9407ae02577c\",...             200   \n",
      "34  {\"id\":\"cmpl-07c8f432f07245b1b6a95d6e0b57d395\",...             200   \n",
      "35  {\"id\":\"cmpl-0e1fbaa921404a6f81687cf70fc3c408\",...             200   \n",
      "36  {\"id\":\"cmpl-cd257032966842b9b200c94322d1b831\",...             200   \n",
      "37  {\"id\":\"cmpl-327c459c2ace497bac874ae7d1da5097\",...             200   \n",
      "38  {\"id\":\"cmpl-1dc9636990864559ba8467330cba0fdb\",...             200   \n",
      "39  {\"id\":\"cmpl-260d31879c4246dd8f2868a34e155780\",...             200   \n",
      "40  {\"id\":\"cmpl-61cf3ef7a4c34d6abf9ffdb3c1bf06d7\",...             200   \n",
      "\n",
      "   Time (seconds)  \n",
      "0       11.955998  \n",
      "1       16.866871  \n",
      "2       23.211112  \n",
      "3       24.215682  \n",
      "4       29.242361  \n",
      "5       11.899663  \n",
      "6       16.804777  \n",
      "7       22.991990  \n",
      "8       24.013633  \n",
      "9       23.999068  \n",
      "10      30.563562  \n",
      "11      35.098950  \n",
      "12      45.049624  \n",
      "13      47.554481  \n",
      "14      47.667985  \n",
      "15      50.724915  \n",
      "16      57.903973  \n",
      "17      59.403525  \n",
      "18      64.972813  \n",
      "19      70.498108  \n",
      "20      71.063867  \n",
      "21      77.720211  \n",
      "22      80.583613  \n",
      "23      11.736405  \n",
      "24      16.532023  \n",
      "25      23.037328  \n",
      "26      23.682317  \n",
      "27      30.811249  \n",
      "28      34.905608  \n",
      "29      45.187069  \n",
      "30      47.688564  \n",
      "31      47.283097  \n",
      "32      50.232059  \n",
      "33      57.984325  \n",
      "34      59.392028  \n",
      "35      59.375810  \n",
      "36      64.721995  \n",
      "37      70.886595  \n",
      "38      70.703407  \n",
      "39      77.427002  \n",
      "40      80.333652  \n"
     ]
    }
   ],
   "source": [
    "# #Model Inference(Request) Same Payload\n",
    "if __name__ == \"__main__\":\n",
    "    # Using the generator function to read lines \n",
    "    prompts = list(read_payloads(request_payload_file))\n",
    "    index=0\n",
    "    global df\n",
    "    for i in range(1):\n",
    "        print(f\"loop {i}+++++++++++++++++++++++++++++\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "            futures = [executor.submit(inference, srno, payload) for srno in range(30)]\n",
    "            concurrent.futures.wait(futures)\n",
    "    save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
