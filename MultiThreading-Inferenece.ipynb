{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85065d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time, random\n",
    "import os, json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "# from functools import partial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddec33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"http://vllm-serving-service:8888/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "# request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "request_payload_file = '/data/Promptshett_codegen_50.txt'\n",
    "report_path = '/data/vLLM_50prompts.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b6c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Prompt_No, Prompt, Response, Response_status, Time (seconds)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://refract.fosfor.com/magiccodermodel/6188a3e2-bc43-444e-bfaa-8159fca71b3a/score\"\n",
    "url = \"http://vllm-serving-service:8888/magicoder/v1/completions\"\n",
    "# lltoken = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"\n",
    "# request_payload_file = '/data/Magicoder_payloads.txt'\n",
    "request_payload_file = '/data/Promptshett_codegen_50.txt'\n",
    "report_path = '/data/vLLM_50prompts.csv'\n",
    "df = pd.DataFrame(columns=['Prompt_No', 'Prompt', 'Response', 'Response_status', 'Time (seconds)'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "998fb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=[\"\"\"You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
    "follow instruction and response accuratly. finally only generate respose without instruction. \n",
    " \n",
    "@@Instruction\n",
    "this is the sample dbt model\n",
    "with customer_revenue as (\n",
    "select\n",
    "customer_id,\n",
    "sum(amount) as total_revenue\n",
    "from\n",
    "{ ref('orders') }\n",
    "group by 1\n",
    ")\n",
    " \n",
    "select\n",
    "c.customer_id,\n",
    "c.first_name,\n",
    "c.last_name,\n",
    "cr.total_revenue\n",
    "from\n",
    "{ source('master_data','customers') } c\n",
    "left join customer_revenue cr on c.customer_id = cr.customer_id\n",
    "\n",
    "@@response\n",
    "Below is the sample dbt model documentation generated for above instruction dbt model:\n",
    " \n",
    "* Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
    "* Dependencies:\n",
    "* orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
    "* customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
    "* Transformation:\n",
    "* The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
    "* The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
    "* Example Usage:  The resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
    "\n",
    "@@ Instruction\n",
    "create similar dbt model documentation for following dbt model code\n",
    " {% snapshot users_snapshot %}  \n",
    " \n",
    "{{\n",
    "  config(      \n",
    "    target_schema='snapshots',      \n",
    "    strategy='timestamp',      \n",
    "    unique_key='id',      \n",
    "    updated_at='updated_at'    \n",
    "  )  \n",
    "}}  \n",
    " \n",
    "  select * \n",
    "  from {{ source('raw','users') }}\n",
    " \n",
    "{% endsnapshot %}\n",
    "\n",
    "@@ response\"\"\",\n",
    "       \"Generate a DBT model which gives me variants of the products which has highest sales\",\n",
    "       \"Construct a DBT view model in the 'staging' schema, linking 'jaffle_shop' orders with payment information from 'stg_payments', summarizing successful payments per order, and merging with order details to handle potential missing payment scenarios.\",\n",
    "       \"Define an incremental dbt model named user_activity_daily with a unique key on date_day for daily active users. Implement the 'delete+insert' strategy for incremental updates.\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " payload = {\"prompt\": \"Problem: Create an animated dropdown menu in CSS that appears when a button is clicked.Input: Button element selector, dropdown menu element selector.Output: None (animate the dropdown menu).\", \n",
    "           \"max_tokens\": 200,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd035b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\": prompt, \n",
    "           \"max_tokens\": 2400,\n",
    "           \"temperature\": 0,\n",
    "           \"model\": \"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c55110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_payloads(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            prompt = line.strip()\n",
    "#             prompt = json.loads(line.strip())\n",
    "            yield prompt\n",
    "#             yield prompt['payload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90a0dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def calculate_execution_time(*args, **kwargs):\n",
    "        global df\n",
    "        start_time = time.time()\n",
    "        result, a,b= func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        data = {'Prompt_No':b,'Prompt':a,'Response':result.text, 'Response_status':result.status_code, 'Time (seconds)':f'{execution_time:.6f}'}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        print(f\"Execution time: {execution_time:.6f} seconds \\n\\n\")\n",
    "        return result,a,b\n",
    "    return calculate_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f946126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(file_path, df):\n",
    "    print(\"Saving report\\n\", df)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed2a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_decorator\n",
    "def inference(prompt_index, payload_data=None):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, json=payload_data)\n",
    "#     print(f\"Prompt {prompt_index}==> {payload_data['prompt']} \\n {response.text}\")\n",
    "    print(f\"Prompt {prompt_index}==> Response \\n {response.text}\")\n",
    "    return response, payload_data['prompt'], prompt_index\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b1003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_worker(thread, payload):\n",
    "    prompts = read_payloads(request_payload_file)\n",
    "    try:\n",
    "        for line, prompt in enumerate(prompts,start=0):\n",
    "            payload = {**payload, 'prompt': prompt}\n",
    "            print(f\"Prompting prompt {line+1}\")\n",
    "            a,b,c,_ = inference(line, payload)\n",
    "            print(f\"Finished Prompting prompt {line+1}\")\n",
    "    except Exception as e:\n",
    "        print(a,b,c)\n",
    "        print(f\"Error in thread {thread} - prompt {line}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c706b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Inference(Request)\n",
    "# if __name__ == \"__main__\":\n",
    "#     global df\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "#         futures = [executor.submit(my_worker, _, payload) for _ in range(30)]\n",
    "#         concurrent.futures.wait(futures)\n",
    "#     save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78831f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "loop 0+++++++++++++++++++++++++++++\n",
      "Prompt 9==> Response \n",
      " {\"id\":\"cmpl-58d71c5ad4fe48b1877d35e1bb6f4a20\",\"object\":\"text_completion\",\"created\":2200450,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\nAssuming you have two tables:\\n\\n1. `employees` table with columns: `employee_id`, `name`, `country`, `client_id`\\n2. `clients` table with columns: `client_id`, `client_name`, `country`\\n\\nThe SQL query would look something like this:\\n\\n```sql\\nSELECT e.employee_id, e.name, e.country, c.client_name, c.country\\nFROM employees e\\nJOIN clients c ON e.client_id = c.client_id\\nWHERE c.country = 'US'\\n```\\n\\nThis SQL statement will join the `employees` and `clients` tables on the `client_id` column, and then filter the results to only include rows where the `country` of the `clients` table is 'US'. The resulting table will contain the `employee_id`, `name`, `country` of the employee, `client_name`, and `country` of the client for all employees who work for US-based clients.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":26,\"total_tokens\":268,\"completion_tokens\":242}}\n",
      "Execution time: 13.330764 seconds \n",
      "\n",
      "\n",
      "Prompt 1==> Response \n",
      " {\"id\":\"cmpl-a2684cab39c14f94b8545c100f269be0\",\"object\":\"text_completion\",\"created\":2200449,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\n```sql\\n{{ config(materialized='table', unique_key='customer_id') }}\\n\\nwith customers as (\\n    select * from {{ ref('stg_customers') }}\\n),\\n\\nage_groups as (\\n    select \\n        customer_id,\\n        case \\n            when age >= 18 then 'Adult'\\n            else 'Minor'\\n        end as age_group\\n    from customers\\n)\\n\\nselect * from age_groups\\n```\\n\\nIn this model, we first define a CTE (Common Table Expression) named `customers` that selects from the `stg_customers` table. Then, we define another CTE named `age_groups` that categorizes customers into 'Adult' or 'Minor' based on their age. The `case` statement is used to assign the appropriate age group to each customer. Finally, we select from the `age_groups` CTE to create the final table.\\n\\nPlease replace `{{ ref('stg_customers') }}` with the actual name of your source table.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":72,\"total_tokens\":314,\"completion_tokens\":242}}\n",
      "Execution time: 13.611926 seconds \n",
      "\n",
      "\n",
      "Prompt 4==> Response \n",
      " {\"id\":\"cmpl-0f89e10431b74538858785ab020cf287\",\"object\":\"text_completion\",\"created\":2200449,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\n```sql\\n{{\\n    config(\\n        target_database='analytics',\\n        target_schema='snapshots',\\n        unique_key='activity_id',\\n        strategy='timestamp',\\n        updated_at='activity_date',\\n    )\\n}}\\n\\nselect\\n    ua.*,\\n    u.username,\\n    u.email\\nfrom\\n    public.user_activity ua\\nleft join\\n    public.users u on ua.user_id = u.user_id\\n```\\n\\nThis snapshot will capture changes in the 'user_activity' table and update the 'user_activity_snapshot' table in the 'analytics.snapshots' schema. The 'activity_id' column will be used as the unique key to identify changes. The 'activity_date' column will be used as the update timestamp. The snapshot will retrieve data from 'public.user_activity' and left join it with 'public.users' on 'user_id'. The 'username' and 'email' columns from the 'public.users' table will be included in the snapshot.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":97,\"total_tokens\":342,\"completion_tokens\":245}}\n",
      "Prompt 0==> Response \n",
      " {\"id\":\"cmpl-c02a49a1d6e34af794f8e1a9293217d8\",\"object\":\"text_completion\",\"created\":2200449,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\n```sql\\n{{\\n    config(\\n        target_database='analytics',\\n        target_schema='snapshots',\\n        unique_key='activity_id',\\n        strategy='timestamp',\\n        updated_at='activity_date',\\n    )\\n}}\\n\\nselect\\n    ua.*,\\n    u.username,\\n    u.email\\nfrom\\n    public.user_activity ua\\nleft join\\n    public.users u on ua.user_id = u.user_id\\n```\\n\\nThis snapshot will capture changes in the 'user_activity' table and update the 'user_activity_snapshot' table in the 'analytics.snapshots' schema. The 'activity_id' column will be used as the unique key to identify changes. The 'activity_date' column will be used as the update timestamp. The snapshot will retrieve data from 'public.user_activity' and left join it with 'public.users' on 'user_id'. The 'username' and 'email' columns from the 'public.users' table will be included in the snapshot.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":97,\"total_tokens\":342,\"completion_tokens\":245}}\n",
      "Execution time: 13.691948 seconds \n",
      "\n",
      "Execution time: 13.772616 seconds \n",
      "\n",
      "\n",
      "\n",
      "Prompt 7==> Response \n",
      " {\"id\":\"cmpl-e2b27ea7417b4086bee91ed79f42943d\",\"object\":\"text_completion\",\"created\":2200450,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\n```sql\\n{{ config(materialized='table') }}\\n\\nwith customer_purchase_details as (\\n    select\\n        c.customer_id,\\n        c.first_name,\\n        c.last_name,\\n        o.order_id,\\n        o.order_date,\\n        p.product_id,\\n        p.product_name,\\n        oi.quantity,\\n        oi.price,\\n        oi.quantity * oi.price as total_amount\\n    from {{ ref('customers') }} c\\n    join {{ ref('orders') }} o on c.customer_id = o.customer_id\\n    join {{ ref('order_items') }} oi on o.order_id = oi.order_id\\n    join {{ ref('products') }} p on oi.product_id = p.product_id\\n)\\n\\nselect * from customer_purchase_details\\n```\\n\\nThis model will create a table with the required details. The unique key 'customer_id' is materialized by selecting distinct customer_id from the result.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":67,\"total_tokens\":316,\"completion_tokens\":249}}\n",
      "Execution time: 13.718072 seconds \n",
      "\n",
      "\n",
      "Prompt 5==> Response \n",
      " {\"id\":\"cmpl-222169e4428949a18e869698cc8d0dfa\",\"object\":\"text_completion\",\"created\":2200450,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\n\\n```sql\\n{{ config(materialized='view') }}\\n\\nwith customer_purchases as (\\n    select\\n        o.customer_id,\\n        p.product_id,\\n        count(*) as purchase_count\\n    from {{ ref('orders') }} o\\n    join {{ ref('order_items') }} oi on o.order_id = oi.order_id\\n    join {{ ref('products') }} p on oi.product_id = p.product_id\\n    group by o.customer_id, p.product_id\\n)\\n\\nselect\\n    cp.customer_id,\\n    cp.product_id,\\n    cp.purchase_count,\\n    p.product_name,\\n    p.product_category,\\n    p.product_price,\\n    p.product_description\\nfrom customer_purchases cp\\njoin {{ ref('products') }} p on cp.product_id = p.product_id\\n```\\n\\nThis view will generate a table of customer purchases for each product, including the product's name, category, price, and description. This can be used to generate product recommendations for each customer based on their purchase history.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":55,\"total_tokens\":322,\"completion_tokens\":267}}\n",
      "Execution time: 14.753821 seconds \n",
      "\n",
      "\n",
      "Prompt 2==> Response \n",
      " {\"id\":\"cmpl-ea5a95b81242470493bfa1cbd8960925\",\"object\":\"text_completion\",\"created\":2200449,\"model\":\"/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66\",\"choices\":[{\"index\":0,\"text\":\"\\n\\nI have a table named \\\"orders\\\" which has columns like order_id, customer_id, product_id, recommendation_score.\\n\\nI want to generate a dbt model which gives me product details which has similar recommendation_score for each customer.\\n\\nHere is what I have tried:\\n\\n```sql\\n{{ config(materialized='table') }}\\n\\nwith similar_recommendation_score as (\\n    select \\n        customer_id,\\n        product_id,\\n        recommendation_score,\\n        count(*) as count_of_similar_recommendation_score\\n    from \\n        orders\\n    group by \\n        customer_id,\\n        product_id,\\n        recommendation_score\\n    having \\n        count(*) > 1\\n)\\n\\nselect \\n    product_id,\\n    product_name,\\n    product_category,\\n    product_price\\nfrom \\n    similar_recommendation_score\\njoin \\n    products on similar_recommendation_score.product_id = products.product_id\\n```\\n\\nThis query gives me the product_id, product_name, product_category, product_price for each customer who has similar recommendation_score for a product.\\n\\nHowever, I want to get the product details for each customer who has similar recommendation_score for each product.\\n\\nHow can I modify the query to get the desired output?\\n\\nI am using dbt version 1.0.0.\\n\\nThanks in advance.\",\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":22,\"total_tokens\":358,\"completion_tokens\":336}}\n",
      "Execution time: 18.369120 seconds \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d01eac49e1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prompt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrno\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     save_report(report_path, df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d01eac49e1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prompt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrno\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     save_report(report_path, df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Model Inference(Request) Same Payload\n",
    "if __name__ == \"__main__\":\n",
    "    # Using the generator function to read lines \n",
    "    prompts = list(read_payloads(request_payload_file))\n",
    "    print(len(prompts))\n",
    "    index=0\n",
    "    global df\n",
    "    for i in range(1000):\n",
    "        print(f\"loop {i}+++++++++++++++++++++++++++++\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = [executor.submit(inference, srno, {**payload, 'prompt': prompts[random.randint(0,49)]}) for srno in range(10)]\n",
    "            concurrent.futures.wait(futures)\n",
    "    save_report(report_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
