{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd42bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce2827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "'''user = REFRACT.FOSFOR@LNTINFOTECH.COM\n",
    "password = Password321\n",
    "account = fya62509.us-east-1\n",
    "warehouse = FOSFOR_REFRACT\n",
    "database = FOSFOR_REFRACT\n",
    "schema = SALES\n",
    "role = FOSFOR_REFRACT'''    \n",
    "\n",
    "# Snowflake connection parameters\n",
    "snowflake_account = 'rwb76633'\n",
    "snowflake_user = 'Ravi'\n",
    "snowflake_password = 'Kayakave@1983'\n",
    "snowflake_database = 'TUTORIAL_DB'\n",
    "snowflake_schema = 'DATA_SCHEMA'\n",
    "snowflake_stage = 'MAGICODER2'\n",
    "role = 'TEST_ROLE'\n",
    "\n",
    "# snowflake_account = 'fya62509.us-east-1'\n",
    "# snowflake_user = 'REFRACT.FOSFOR@LNTINFOTECH.COM'\n",
    "# snowflake_password = 'Password321'\n",
    "# snowflake_database = 'FOSFOR_REFRACT'\n",
    "# snowflake_schema = 'SALES'\n",
    "# snowflake_stage = 'MAGICODER'\n",
    " \n",
    "# Connect to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "   user=snowflake_user,\n",
    "   password=snowflake_password,\n",
    "   account=snowflake_account,\n",
    "   session_parameters={\n",
    "      'PYTHON_CONNECTOR_QUERY_RESULT_FORMAT': 'json'\n",
    "   },\n",
    "   database=snowflake_database,\n",
    "   schema=snowflake_schema,\n",
    "   role=role,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c53233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.connection.SnowflakeConnection at 0x7f3ddc2d0340>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4e9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls -lrt /llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f901ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    " \n",
    "# Upload file to stage (example using Pandas)\n",
    "#file_path = '/llmmodels/models--ise-uiuc--Magicoder-S-DS-6.7B/snapshots/cff055b1e110cbe75c0c3759bd436299c6d6bb66/special_tokens_map.json'\n",
    "# df = pd.read_csv(file_path)\n",
    "#cur.execute(f\"PUT file://{file_path} @{snowflake_stage}/magicoder_model AUTO_COMPRESS = FALSE\")\n",
    "#cur.execute(\"Select * from Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fa29f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"You are an exceptional dbt analytics engineer writes dbt models, also creates very precise and accurate functional documentation to ensure any layman understands the code written by you.\n",
    "        follow instruction and response accuratly. finally only generate respose without instruction. \n",
    "        \n",
    "        @@Instruction\n",
    "        this is the sample dbt model\n",
    "        with customer_revenue as (\n",
    "        select\n",
    "        customer_id,\n",
    "        sum(amount) as total_revenue\n",
    "        from\n",
    "        {{ ref('orders') }}\n",
    "        group by 1\n",
    "        )\n",
    "        \n",
    "        select\n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        cr.total_revenue\n",
    "        from\n",
    "        {{ source('master_data','customers') }} c\n",
    "        left join customer_revenue cr on c.customer_id = cr.customer_id\n",
    "\n",
    "        @@Response\n",
    "        Below is the sample dbt model documentation generated for above instruction dbt model:\n",
    "        \n",
    "        * Overview: This dbt model calculates the total revenue per customer by leveraging the data from the orders model and customers source. \n",
    "        * Dependencies:\n",
    "        * orders: dbt model that contains information about individual orders, including the customer_id and amount.\n",
    "        * customers: dbt source contains customer details, including customer_id, first_name, and last_name.\n",
    "        * Transformation:\n",
    "        * The CTE 'customer_revenue' aggregates the total revenue for each customer by summing the amount from the orders model. It utilizes the customer_id field for grouping.\n",
    "        * The final output includes customer details from the customers table (c) and their corresponding total revenue from the customer_revenue CTE (cr). The join is performed using the customer_id field.\n",
    "        * Example Usage:\tThe resulting model can be used for various analytical purposes, such as identifying high-value customers or generating reports on customer revenue.\n",
    "\n",
    "        @@ Instruction\n",
    "        create similar dbt model documentation for following dbt model code\n",
    "            \"create document for following dbt code {% snapshot users_snapshot %}  \n",
    "\n",
    "    {{\n",
    "      config(      \n",
    "        target_schema='snapshots',      \n",
    "        strategy='timestamp',      \n",
    "        unique_key='id',      \n",
    "        updated_at='updated_at'    \n",
    "      )  \n",
    "    }}  \n",
    "\n",
    "      select * \n",
    "      from {{ source('raw','users') }}\n",
    "\n",
    "    {% endsnapshot %}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "93a7bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = r\"\"\"Construct a DBT view model in the 'staging' schema, linking 'jaffle_shop' orders with payment information from 'stg_payments', summarizing successful payments per order, and merging with order details to handle potential missing payment scenarios.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c91ff7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.replace(\"'\", \"''\")\n",
    "prompt = prompt.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "494c4137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Generate documentation for following dbt code  {{ config(materialized=''table'') }}  with source as (     select * from {{ source(''src_table'', ''employees'') }} ),  parsed as (     select         id,         PARSE_JSON(json_column):field1::varchar as field1,         PARSE_JSON(json_column):field2::int as field2,         PARSE_JSON(json_column):field3::timestamp as field3     from source )  select * from parsed\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d63b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Generate bdt code to join supply and demand column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e15a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_arg ={\"prompt\":prompt, \"max_tokens\": 2000, \"temperature\": 0, \"model\": \"/data/magicoder_model\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e80ce956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"Construct a DBT view model in the 'staging' schema, linking 'jaffle_shop' orders with payment information from 'stg_payments', summarizing successful payments per order, and merging with order details to handle potential missing payment scenarios.\",\n",
       " 'max_tokens': 2000,\n",
       " 'temperature': 0,\n",
       " 'model': '/data/magicoder_model'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2ef92e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0dc60324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT magicoder_udf(parse_json('{\"prompt\":\"Assume you are a DBT query optimizer, Optimize this DBT query and if possible modularize this query using CTE: '''''' SELECT ACC.ACCOUNT_ID AS ACCOUNT_ID ,CASE WHEN OUTER.ACCOUNT_ID IS NOT NULL THEN ''Y'' ELSE ''N'' END AS DONATED ,NVL(NULLIF(SPLIT_PART(OUTER.FIRST_OPPORTUNITY_DTL, ''|'', 1), 0),0) AS FIRST_GIFT_AMOUNT ,NULLIF(SPLIT_PART(OUTER.FIRST_OPPORTUNITY_DTL, ''|'', 2),'''') AS FIRST_GIFT_DATE ,NVL(OUTER.TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_HC,0) AS TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_HC ,NVL(OUTER.TOTAL_NUMBER_OF_GIFTS_ALL_TIME_HC,0) AS TOTAL_NUMBER_OF_GIFTS_ALL_TIME_HC ,NVL(OUTER.TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_SC,0) AS TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_SC ,NVL(OUTER.TOTAL_NUMBER_OF_GIFTS_ALL_TIME_SC,0) AS TOTAL_NUMBER_OF_GIFTS_ALL_TIME_SC FROM \"\"DIM_DB\"\".\"\"CORE\"\".\"\"DIM_ACCOUNT\"\" ACC LEFT JOIN (SELECT INNER.ACCOUNT_ID ,ANY_VALUE(INNER.FIRST_OPPORTUNITY_DTL) AS FIRST_OPPORTUNITY_DTL ,ANY_VALUE(INNER.LAST_OPPORTUNITY_DTL) AS LAST_OPPORTUNITY_DTL ,ANY_VALUE(INNER.SMALLEST_OPPORTUNITY_DTL) AS SMALLEST_OPPORTUNITY_DTL ,ANY_VALUE(INNER.LARGEST_OPPORTUNITY_DTL)  AS LARGEST_OPPORTUNITY_DTL ,AVG(INNER.OPPORTUNITY_AMOUNT) AS AVERAGE_OPPORTUNITY_AMOUNT ,ARRAY_SIZE(ARRAY_AGG( DISTINCT INNER.FISCAL_YEAR)  WITHIN GROUP (ORDER BY INNER.FISCAL_YEAR DESC)) AS NUMBER_OF_YEARS_DONATING ,SUM(INNER.CURR_PREV_CONSECUTIVE_YEAR_DONATING_FLAG) AS CURR_PREV_NUMBER_OF_CONSECUTIVE_YEAR_DONATING ,\"\"DIM_DB\"\".\"\"CORE\"\".\"\"NUM_OF_MAX_CONSQ_YEARS_CALC_FN\"\"(ARRAY_AGG( DISTINCT INNER.FISCAL_YEAR) WITHIN GROUP (ORDER BY INNER.FISCAL_YEAR DESC)) AS MAXIMUM_NUMBER_OF_CONSECUTIVE_YEAR_DONATING ,GET(ARRAY_AGG(INNER.CAL_YEAR) WITHIN GROUP (ORDER BY INNER.TOTAL_DONATION_OVER_CAL_YEAR DESC, INNER.CAL_YEAR DESC), 0) AS BEST_GIFT_CAL_YEAR ,MAX(INNER.TOTAL_DONATION_OVER_CAL_YEAR) AS BEST_GIFT_CAL_YEAR_TOTAL_AMOUNT ,GET(ARRAY_AGG(INNER.FISCAL_YEAR) WITHIN GROUP (ORDER BY INNER.TOTAL_DONATION_OVER_FISCAL_YEAR DESC, INNER.FISCAL_YEAR DESC),0) AS BEST_GIFT_FISCAL_YEAR ,MAX(INNER.TOTAL_DONATION_OVER_FISCAL_YEAR) AS BEST_GIFT_FISCAL_YEAR_TOTAL_AMOUNT ,SUM(INNER.AMOUNTS_OF_GIFTS_ALL_TIME_HC) AS TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_HC ,SUM(INNER.IS_DONATION_OF_GIFTS_ALL_TIME_HC) AS TOTAL_NUMBER_OF_GIFTS_ALL_TIME_HC ,SUM(INNER.AMOUNTS_OF_GIFTS_ALL_TIME_SC) AS TOTAL_AMOUNTS_OF_GIFTS_ALL_TIME_SC ,SUM(INNER.IS_DONATION_OF_GIFTS_ALL_TIME_SC) AS TOTAL_NUMBER_OF_GIFTS_ALL_TIME_SC ,ANY_VALUE(INNER.CURR_CAL_YEAR) AS CURR_CAL_YEAR ,ANY_VALUE(INNER.CURR_FISCAL_YEAR) AS CURR_FISCAL_YEAR FROM (SELECT REV.ACCOUNT_ID ,FIRST_VALUE(REV.CONC_DTL) OVER(PARTITION BY REV.ACCOUNT_ID ORDER BY REV.OPPORTUNITY_CLOSEDATE, REV.OPPORTUNITY_ID ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS FIRST_OPPORTUNITY_DTL ,LAST_VALUE(REV.CONC_DTL) OVER(PARTITION BY REV.ACCOUNT_ID ORDER BY REV.OPPORTUNITY_CLOSEDATE, REV.OPPORTUNITY_ID ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS LAST_OPPORTUNITY_DTL ,FIRST_VALUE(REV.CONC_DTL) OVER(PARTITION BY REV.ACCOUNT_ID ORDER BY REV.OPPORTUNITY_AMOUNT, REV.OPPORTUNITY_CLOSEDATE, REV.OPPORTUNITY_ID ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS SMALLEST_OPPORTUNITY_DTL ,LAST_VALUE(REV.CONC_DTL) OVER(PARTITION BY REV.ACCOUNT_ID ORDER BY REV.OPPORTUNITY_AMOUNT, REV.OPPORTUNITY_CLOSEDATE, REV.OPPORTUNITY_ID ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS LARGEST_OPPORTUNITY_DTL ,CASE WHEN FIRST_VALUE(REV.FISCAL_YEAR) OVER (PARTITION BY REV.ACCOUNT_ID ORDER BY REV.FISCAL_YEAR DESC) < (YEAR(CURRENT_DATE()) -1) THEN 0 WHEN  REV.FI SCAL_YEAR + DENSE_RANK() OVER (PARTITION BY REV.ACCOUNT_ID ORDER BY REV.FISCAL_YEAR DESC) - ROW_NUMBER() OVER (PARTITION BY REV.ACCOUNT_ID,REV.FISCAL_YE AR ORDER BY REV.FISCAL_YEAR DESC) = FIRST_VALUE(REV.FISCAL_YEAR) OVER (PARTITION BY REV.ACCOUNT_ID ORDER BY REV.FISCAL_YEAR DESC) THEN 1 ELSE 0 END CURR_PREV_CONSECUTIVE_YEAR_DONATING_FLAG ,SUM(REV.OPPORTUNITY_AMOUNT) OVER(PARTITION BY REV.ACCOUNT_ID, REV.CAL_YEAR) AS TOTAL_DONATION_OVER_CAL_YEAR ,SUM(REV.OPPORTUNITY_AMOUNT) OVER(PARTITION BY REV.ACCOUNT_ID, REV.FISCAL_YEAR) AS TOTAL_DONATION_OVER_FISCAL_YEAR ,CASE WHEN REV.OPPORTUNITY_TYPE_HARD_SOFT = ''Direct Credit'' THEN REV.OPPORTUNITY_AMOUNT ELSE 0 END AS AMOUNTS_OF_GIFTS_ALL_TIME_HC ,CASE WHEN REV.OPPORTUNITY_TYPE_HARD_SOFT = ''Direct Credit'' THEN 1 ELSE 0 END AS IS_DONATION_OF_GIFTS_ALL_TIME_HC ,CASE WHEN REV.OPPORTUNITY_TYPE_HARD_SOFT = ''Indirect Credit'' THEN REV.OPPORTUNITY_AMOUNT ELSE 0 END AS AMOUNTS_OF_GIFTS_ALL_TIME_SC ,CASE WHEN REV.OPPORTUNITY_TYPE_HARD_SOFT = ''Indirect Credit'' THEN 1 ELSE 0 END AS IS_DONATION_OF_GIFTS_ALL_TIME_SC ,REV.OPPORTUNITY_AMOUNT ,REV.CAL_YEAR ,REV.FISCAL_YEAR ,REV.CURR_CAL_YEAR ,REV.CURR_FISCAL_YEAR FROM (SELECT ARV.OPPORTUNITY_TYPE_HARD_SOFT ,ARV.OPPORTUNITY_DONATIONTYPE ,ARV.ACCOUNT_ID ,ARV.OPPORTUNITY_AMOUNT ,ARV.OPPORTUNITY_CLOSEDATE ,ARV.OPPORTUNITY_CAMPAIGN_NAME ,ARV.OPPORTUNITY_CAMPAIGN_DIVISIONAL_PROGRAM ,ARV.OPPORTUNITY_ID ,ARV.OPPORTUNITY_VEHICLE_TYPE ,ARV.OPPORTUNITY_VEHICLE_SUBTYPE ,C.CONTENT_MESSAGING_CATEGORY__C AS CONTENT_MESSAGING_CATEGORY ,YEAR(ARV.OPPORTUNITY_CLOSEDATE) AS CAL_YEAR ,DD.FISCAL_YEAR AS FISCAL_YEAR ,YEAR(CURRENT_DATE()) AS CURR_CAL_YEAR ,DD_CURR.FISCAL_YEAR AS CURR_FI.SCAL_YEAR ,TO_CHAR(CURRENT_DATE(),''MM-DD'') AS CURR_DATE_MM_DD ,NVL(ARV.OPPORTUNITY_AMOUNT,0) || ''|'' || NVL(ARV.OPPORTUNITY_CLOSEDATE ::VARCHAR, '''') || ''|'' || NVL(ARV.OPPORTUNITY_CAMPAIGN_ID, '''') || ''|'' || NVL(ARV.O PPORTUNITY_CAMPAIGN_NAME, '''') || ''|'' || NVL(C.CONTENT_MESSAGING_CATEGORY__C, '''') || ''|'' || NVL(ARV.OPPORTUNITY_CAMPAIGN_DIVISIONAL_PROGRAM, '''') || ''|'' | |  NVL(ARV.OPPORTUNITY_ID, '''') || ''|'' || NVL(ARV.OPPORTUNITY_VEHICLE_TYPE, '''') || ''|'' || NVL(ARV.OPPORTUNITY_VEHICLE_SUBTYPE, '''') || ''|'' || NVL(DD.FISCAL_YEAR::VARCHAR,'''')  AS CONC_DTL FROM REPORTING_DB.SEMANTIC.ALL_REVENUE_V ARV LEFT JOIN DIM_DB.CORE.DIM_DATE DD ON ARV.OPPORTUNITY_CLOSEDATE = DD.DATE LEFT JOIN DIM_DB.CORE.DIM_DATE DD_CURR ON CURRENT_DATE() = DD_CURR.DATE LEFT JOIN STG_DB.CRM_STAGE.CAMPAIGN_S C ON ARV.OPPORTUNITY_CAMPAIGN_ID = C.ID WHERE ARV.ACCOUNT_ID IS NOT NULL AND (NVL(ARV.OPPORTUNITY_AMOUNT,0) <> 0) AND NVL(ARV.OPPORTUNITY_CAMPAIGN_DIVISIONAL_PROGRAM, ''DUMMY'') NOT IN (''Type_Kind'',''Type_Gifts'') AND NVL(ARV.OPPORTUNITY_DONATIONTYPE, ''DUMMY'') <> ''Type_Gifts'' AND NVL(ARV.OPPORTUNITY_VEHICLE_TYPE, ''DUMMY'') NOT IN (''Type_Kind'',''Type_Gifts'')) AS REV ) AS INNER GROUP BY INNER.ACCOUNT_ID ) AS OUTER ON ACC.ACCOUNT_ID = OUTER.ACCOUNT_ID LEFT JOIN (SELECT ACCOUNT_ID, COUNT(*) AS TOTAL_NUMBER_OF_IN_KIND_GIFTS , SUM(OPPORTUNITY_AMOUNT) AS TOTAL_AMOUNT_OF_IN_KIND_GIFTS FROM REPORTING_DB.SEMANTIC.ALL_REVENUE_V WHERE OPPORTUNITY_CAMPAIGN_DIVISIONAL_PROGRAM IN (''Type_Kind'',''Type_Gifts'') OR OPPORTUNITY_DONATIONTYPE = ''Type_Gifts'' OR OPPORTUNITY_VEHICLE_TYPE IN (''Type_Kind'',''Type_Gifts'') GROUP BY ACCOUNT_ID) AS ARV1 ON ACC.ACCOUNT_ID = ARV1.ACCOUNT_ID WHERE ACC.ACCOUNT_ISDELETED = FALSE'''''', Kindly give the response strictly in this format only: OPTIMIZED CODE: ```optimized code``` and then, EXPLAINATI ON: explaination on how you optimized it. The most import instruction is that output of original query and optimized query should be exactly same and stick to specified format.\", \"max_tokens\": 2000, \"temperature\": 0, \"model\": \"/data/magicoder_model\"}'));\n"
     ]
    }
   ],
   "source": [
    "arg = '{\"prompt\":'+'\"'+prompt+'\"'+', \"max_tokens\": 2000, \"temperature\": 0, \"model\": \"/data/magicoder_model\"}'\n",
    "warehouse = 'USE WAREHOUSE TUTORIAL_WAREHOUSE;'\n",
    "query = f\"SELECT magicoder_udf(parse_json('{arg}'));\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ed57b081",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "100069 (22P02): Error parsing JSON: missing comma, pos 753",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(warehouse)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/connector/cursor.py:1136\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1133\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1134\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1136\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 100069 (22P02): Error parsing JSON: missing comma, pos 753"
     ]
    }
   ],
   "source": [
    "cur.execute(warehouse)\n",
    "cur.execute(query)\n",
    "result = cur.fetchall()\n",
    "print(json.loads(result[0][0])['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab750a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('{\\n  \"choices\": [\\n    {\\n      \"finish_reason\": \"stop\",\\n      \"index\": 0,\\n      \"logprobs\": null,\\n      \"text\": \"\"\\n    }\\n  ],\\n  \"created\": 900528,\\n  \"id\": \"cmpl-691f59d7581040858ef60c101927dfdd\",\\n  \"model\": \"/data/magicoder_model\",\\n  \"object\": \"text_completion\",\\n  \"usage\": {\\n    \"completion_tokens\": 1,\\n    \"prompt_tokens\": 74,\\n    \"total_tokens\": 75\\n  }\\n}',)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39daa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Obtain a session token.\n",
    "token_data = conn._rest._token_request('ISSUE')\n",
    "token_extract = token_data['data']['sessionToken']\n",
    "\n",
    "# Create a request to the ingress endpoint with authz.\n",
    "token = f'\\\"{token_extract}\\\"'\n",
    "# Set this to the ingress endpoint URL for your service\n",
    "url = 'http://gowiocnz-zqiseam-ltifosforscsaws.snowflakecomputing.app/vllm/magicoder/v1/completions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2fea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'application/json', 'Authorization': 'Snowflake Token=\"ver:1-hint:14544919633592326-ETMsDgAAAY5Vep50ABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEMk0A8Nx2TZnVqLTbZSljBcAAACA48T2Lr8JKf/dNoQ+63nJH9+QxeHcASiPik2NSxujbZIIjM54+IsUlHcpGUPDwSwQ1JRZTrKIgY0Yuui3WXfMCELevmH/ouvrrg2R/v+F9ovWKUZG0EcY9IHo/Wvqgd1AEOopoYMmfVV+nCaf6UMf9zYA8pcF9Bp2QhsVDUBPBOEAFLlv+fQcuY44iMx5FEtWCNf9RUCD\"'}\n",
      "http://gowiocnz-zqiseam-ltifosforscsaws.snowflakecomputing.app/vllm/magicoder/v1/completions\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "  'Content-Type': 'application/json', 'Authorization': f'Snowflake Token={token}'\n",
    "}\n",
    "print(headers)\n",
    "print(url)\n",
    "#print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15a1367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"Method Not Allowed\"}\n"
     ]
    }
   ],
   "source": [
    "payload = json.dumps({\n",
    "  \"prompt\": \"write a python code to check whether given string is pallindrome\",\n",
    "  \"max_tokens\": 2400,\n",
    "  \"temperature\": 0,\n",
    "  \"model\": \"/data/magicoder_model\"\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json', 'Authorization': f'Snowflake Token={token}'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060fba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66279a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
